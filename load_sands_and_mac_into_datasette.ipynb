{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483a6822-67c2-44c7-8f1b-5c2f0364c20f",
   "metadata": {},
   "source": [
    "# Load data from the Sands and Mac directories into an SQLite database (for use with Datasette)\n",
    "\n",
    "This is a slightly modified version of the [notebook used to process the Tasmanian Post Office Directories](https://glam-workbench.net/libraries-tasmania/tas-pod-add-to-datasette/) in the GLAM Workbench.\n",
    "\n",
    "It creates an SQLite database and accompanying metadata file that can be published online using Datasette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399f1512-526f-4698-9e87-12c9f11f01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the libraries we need.\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from natsort import natsorted, ns\n",
    "from sqlite_utils import Database\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4645cb8c-d946-4d52-970d-0c7a9bcf6f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sands_and_mac_ie.csv\").sort_values(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5e9ebe-c3bb-4251-addb-364276590303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the basic metadata file that will be used by Datasette\n",
    "# The processing steps below will add details for each table/volume into the metadata file\n",
    "# Obviously you'd modify this for a different publication!\n",
    "\n",
    "metadata = {\n",
    "    \"title\": \"Sands & McDougall's directories of Victoria, 1860 to 1974\",\n",
    "    \"description_html\": \"<p>This is an experimental interface to the <a href='https://find.slv.vic.gov.au/discovery/collectionDiscovery?vid=61SLV_INST:SLV&collectionId=81213035910007636'>Sands & MacDougall directories for Victoria from 1860 to 1974</a> which have been digitised and made available by the State Library of Victoria.</p><p>This interface searches for individual lines of text, rather than pages or articles. So it points you straight to entries of interest. Once you've found something, you can view the entry within the context of the complete page, or click back to the SLV to explore further.</p>\",\n",
    "    \"databases\": {\n",
    "        \"sands-mcdougalls-directories-victoria\": {\n",
    "            \"title\": \"Sands & McDougall's directories of Victoria, 1860 to 1974\",\n",
    "            \"source\": \"State Library of Victoria\",\n",
    "            \"source_url\": \"https://find.slv.vic.gov.au/discovery/collectionDiscovery?vid=61SLV_INST:SLV&collectionId=81213035910007636\",\n",
    "            \"tables\": {},\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9d3125-6794-458f-9a1f-6293a476c6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860\n",
      "1865\n",
      "1870\n",
      "1875\n",
      "1880\n",
      "1885\n",
      "1890\n",
      "1895\n",
      "1900\n",
      "1905\n",
      "1910\n",
      "1915\n",
      "1920\n",
      "1925\n",
      "1930\n",
      "1935\n",
      "1940\n",
      "1945\n",
      "1950\n",
      "1955\n",
      "1960\n",
      "1965\n",
      "1970\n",
      "1974\n"
     ]
    }
   ],
   "source": [
    "# Create the database\n",
    "# Change the name as apporpriate!\n",
    "db = Database(Path(\"sands_and_mac\", \"sands-mcdougalls-directories-victoria.db\"), recreate=True)\n",
    "\n",
    "# Create database tables for pages and volumes\n",
    "page_table = db[\"pages\"]\n",
    "vols_table = db[\"volumes\"]\n",
    "\n",
    "# Loop through the directories of each volume created by the harvesting process (above)\n",
    "# Use natsorted so that they're processed in date order\n",
    "vols = natsorted(\n",
    "    [d for d in Path(\"sands_and_mac\").glob(\"sa*\") if d.is_dir()], alg=ns.PATH\n",
    ")\n",
    "\n",
    "for i, vol in df.iterrows():\n",
    "    alma_id = vol[\"Record ID\"]\n",
    "    ie_id = vol[\"ie_id\"]\n",
    "    year = str(vol[\"Date\"])\n",
    "    print(year)\n",
    "    vol_path = [v for v in Path(\"sands_and_mac\").glob(f\"sa{vol['Date']}*\") if v.is_dir()][0]\n",
    "    pages = natsorted(\n",
    "        [p for p in Path(vol_path, \"alto-json\").glob(\"*.ndjson\") if p.is_file()], alg=ns.PATH\n",
    "    )\n",
    "    # Add a record for this volume to the database\n",
    "    vols_table.insert({\"vol_id\": ie_id, \"year\": year, \"alma_id\": alma_id}, pk=\"vol_id\")\n",
    "\n",
    "    # Update the metadata file with details of this volume\n",
    "    metadata[\"databases\"][\"sands-mcdougalls-directories-victoria\"][\"tables\"][\"v\" + year] = {\n",
    "        \"title\": f\"Sands & McDougall's directory of Victoria, {year}\",\n",
    "        \"source\": \"State Library of Victoria\",\n",
    "        \"source_url\": f\"https://viewer.slv.vic.gov.au/?entity={ie_id}&mode=browse\",\n",
    "        \"searchmode\": \"raw\",\n",
    "    }\n",
    "\n",
    "    # Create a table for this volume. For the PO directories I'm using the year as the table name.\n",
    "    # If year isn't available, some other way of naming the table would be necessary, such as the full title.\n",
    "    # Need to add the v prefix because otherwise SQLite indexing fails with unhelpful error message\n",
    "    vol_table = db[\"v\" + year]\n",
    "    lines = []\n",
    "    for page_num, page in enumerate(pages, start=1):\n",
    "        \n",
    "        # text = page.read_text()\n",
    "        page_id = page.stem.split(\"-\")[1]\n",
    "        page_table.insert(\n",
    "            {\"page_id\": page_id, \"page\": page_num, \"vol_id\": ie_id},\n",
    "            pk=(\"page_id\"),\n",
    "            foreign_keys=[(\"vol_id\", \"volumes\")],\n",
    "        )\n",
    "\n",
    "        # Open the text file and loop through the lines\n",
    "        with page.open(\"r\") as ndjson:\n",
    "            line_num = 1\n",
    "            for line in ndjson:\n",
    "                data = json.loads(line)\n",
    "                # Get rid of blank lines\n",
    "                text = data[\"text\"].replace(\"\\n\", \"\").strip()\n",
    "                # If line is not blank, add details to a list of lines from this page\n",
    "                if text:\n",
    "                    lines.append(\n",
    "                        {\n",
    "                            \"page\": page_num,\n",
    "                            \"line\": line_num,\n",
    "                            \"text\": text,\n",
    "                            \"page_id\": page_id,\n",
    "                            \"w\": data[\"w\"],\n",
    "                            \"h\": data[\"h\"],\n",
    "                            \"x\": data[\"x\"],\n",
    "                            \"y\": data[\"y\"],\n",
    "                            \n",
    "                        }\n",
    "                    )\n",
    "                    line_num += 1\n",
    "    # Insert all the lines from this page into the db\n",
    "    try:\n",
    "        vol_table.insert_all(\n",
    "            lines, pk=(\"page\", \"line\"), foreign_keys=[(\"page_id\", \"pages\", \"page_id\")]\n",
    "        )\n",
    "    except IndexError:\n",
    "        print(lines[:100])\n",
    "\n",
    "    # Add a full text index on the line text\n",
    "    vol_table.enable_fts([\"text\"])\n",
    "    # vol_table.optimize()\n",
    "\n",
    "# Save the updated metadata file\n",
    "with open(Path(\"sands_and_mac\", \"datasette-metadata.json\"), \"w\") as md_file:\n",
    "    json.dump(metadata, md_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bd30eae-07b1-4c0b-bc76-8050fc7f2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abb_data = []\n",
    "for year in [1955, 1965, 1974]:\n",
    "    abbrs = pd.read_csv(f\"sands_mac_{year}_abbr.csv\", names=[\"suburb\", \"abbr\"])\n",
    "    for abbr in abbrs.to_dict(orient=\"records\"):\n",
    "        abbr[\"year\"] = year\n",
    "        abb_data.append(abbr)\n",
    "for year in [1905]:\n",
    "    abbrs = pd.read_csv(f\"sands_mac_{year}_abbr.csv\", names=[\"abbr\", \"suburb\"])\n",
    "    for abbr in abbrs.to_dict(orient=\"records\"):\n",
    "        abbr[\"year\"] = year\n",
    "        abb_data.append(abbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e298d6e0-709e-4d3e-8c50-e72a76256257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table abbreviations (suburb, abbr, year)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Database(Path(\"sands_and_mac\", \"sands-mcdougalls-directories-victoria.db\"))\n",
    "db[\"abbreviations\"].insert_all(abb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b5dd2-2da6-4a28-bd0e-18287c054b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
