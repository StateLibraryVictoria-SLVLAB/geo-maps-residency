{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3021c59-a544-487a-a9c5-8faec80316d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Download Sands and Mac PDFs and OCR text\n",
    "\n",
    "This notebook was used to download data from the Sands & Mac directories so I could create a fully-searchable version.\n",
    "\n",
    "I started by downloading all the PDFs, but later found I could get OCR data directly from online versions of the ALTO files. The page images are all available through IIIF, so in the end I didn't really need the PDFs at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4b6cb-8419-4d64-94be-71b9ef295ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests_cache import CachedSession\n",
    "import re\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sess = CachedSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb123ec-5ef7-4340-878e-b6521af84d33",
   "metadata": {},
   "source": [
    "We're starting with a CSV file containing the results of a search for Sands and Mac which was exported from the SLV catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6a750-8311-4c36-b900-413ee436ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file from the catalogue\n",
    "df = pd.read_csv(\"sands_and_mac.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefddfb-699d-4bcd-b6a6-3329322973fc",
   "metadata": {},
   "source": [
    "## Get PDF ids\n",
    "\n",
    "To download a PDF version of a digitised item you need its identifier, and that's not easy to find.\n",
    "\n",
    "If you're starting with an Alma identifier, you first need to get the `IE` identifer from the MARC record.\n",
    "\n",
    "Then you need an identifier that points to the specific PDF representation of the item. The PDF links are created dynamically in the SLV image viewer, so the information is coming from somewhere, but where? I eventually realised that the viewer is loading a JSON file with what I think is data about the digitised item from Rosetta. This file contains identifiers for `small_pdf` and `master_pdf`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd87a90-08b8-41ae-914e-f74dea000e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marc_record(alma_id):\n",
    "    \"\"\"\n",
    "    Gets a text representation of an item's MARC record.\n",
    "    \"\"\"\n",
    "    response = sess.get(\n",
    "        f\"https://find.slv.vic.gov.au/primaws/rest/pub/sourceRecord?docId=alma{alma_id}&vid=61SLV_INST:SLV\"\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def get_marc_value(marc, tag, subfield):\n",
    "    \"\"\"\n",
    "    Gets the value of a tag/subfield from a text version of an item's MARC record.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tag = re.search(rf\"^{tag}\\t.+\", marc, re.M).group(0)\n",
    "        subfield = re.search(rf\"\\${subfield}([^\\$]+)\", tag).group(1)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    return subfield.strip(\" .,\")\n",
    "\n",
    "def get_image_id(alma_id):\n",
    "    \"\"\"\n",
    "    Get the IE image identifier from the MARC record.\n",
    "    These ids are used to construct IIIF manifest urls.\n",
    "    \"\"\"\n",
    "    marc = get_marc_record(alma_id)\n",
    "    try:\n",
    "        image_id = re.search(r\"\\$e(IE\\d+)\", marc).group(1)\n",
    "    except AttributeError:\n",
    "        # print(alma_id)\n",
    "        image_id = \"\"\n",
    "    return image_id\n",
    "\n",
    "def get_pdf_id(ie_id):\n",
    "    # url to get METS info\n",
    "    response = sess.get(f\"https://viewerapi.slv.vic.gov.au/?entity={ie_id}&dc_arrays=1\")\n",
    "    data = response.json()\n",
    "    try:\n",
    "        pdf_id = data[\"summary\"][\"small_pdf\"][\"$ref\"].split(\"][\")[1].strip('\"]')\n",
    "    except KeyError:\n",
    "        pdf_id = data[\"summary\"][\"master_pdf\"][\"$ref\"].split(\"][\")[1].strip('\"]')\n",
    "    return pdf_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef34f1a-2bef-4785-a55a-e2274562f102",
   "metadata": {},
   "source": [
    "Add the `IE` and PDF identifiers to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e22e47-f971-401c-80a5-4da2fc99aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ie_id\"] = df[\"Record ID\"].apply(get_image_id)\n",
    "df[\"pdf_id\"] = df[\"ie_id\"].apply(get_pdf_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c594a46-e655-4fe1-a911-1458ce0d8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c04b8-8c29-4099-987e-6e87bda70e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sands_and_mac_ie.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14737f9a-2e82-4abc-b78e-77945422cc26",
   "metadata": {},
   "source": [
    "## Download PDFs and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc3811-3c48-43de-8ba4-bf4c3090c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_id in df[\"pdf_id\"].to_list():\n",
    "    pdf_url = f\"https://rosetta.slv.vic.gov.au/delivery/DeliveryManagerServlet?dps_func=stream&dps_pid={pdf_id}\"\n",
    "    response = sess.get(pdf_url)\n",
    "    filename = response.headers[\"Content-Disposition\"].split(\"=\")[1].strip('\"')\n",
    "    Path(\"sands_and_mac\", filename).write_bytes(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fa55c-80c3-4a22-a3b3-38c09298e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the PDFs\n",
    "for pdf in Path(\"sands_and_mac\").glob(\"*.pdf\"):\n",
    "    print(pdf.name)\n",
    "    pid = pdf.name.split(\".\")[0]\n",
    "    # Create directory for volume\n",
    "    data_dir = Path(\"sands_and_mac\", pid)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    # Create directories for text and images\n",
    "    text_dir = Path(data_dir, \"text\")\n",
    "    image_dir = Path(data_dir, \"images\")\n",
    "    text_dir.mkdir(exist_ok=True)\n",
    "    image_dir.mkdir(exist_ok=True)\n",
    "    # Open the PDF with PyMuPDF\n",
    "    doc = fitz.open(pdf)\n",
    "    for i, page in enumerate(doc):\n",
    "        # Get images\n",
    "        for xref in page.get_images():\n",
    "            pix = fitz.Pixmap(doc, xref[0])\n",
    "            image_file = Path(image_dir, f\"{pid}-{i+1}.jpg\")\n",
    "            pix.save(image_file)\n",
    "        # Get text\n",
    "        text_path = Path(text_dir, f\"{pid}-{i+1}.txt\")\n",
    "        # The sort option tries to organise the text into a natural reading view.\n",
    "        # However, this doesn't always manage to identify column boundaries, so values from adjacent columns can be munged together.\n",
    "        text = page.get_text(sort=True)\n",
    "        Path(text_path).write_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512376db-7171-4602-9501-a1259c51af6d",
   "metadata": {},
   "source": [
    "## Download ALTO files and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eb556-6f80-4adb-9c20-43db60b8312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tiff_rep(data):\n",
    "    for rep in data[\"representation\"].values():\n",
    "        if rep.get(\"entity_type\") == \"TIFF\" and rep.get(\"representation_code\") == \"HIGH\":\n",
    "            return rep[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ee093-98c3-4f12-b7db-41c58372420a",
   "metadata": {},
   "source": [
    "Download all the ALTO files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9da879-8af3-4925-8760-c342307f75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through volumes, sorted by date\n",
    "for i, vol in df.sort_values(\"Date\").iterrows(): \n",
    "    ie_id = vol[\"ie_id\"]\n",
    "    # Path to volume data\n",
    "    vol_path = [v for v in Path(\"sands_and_mac\").glob(f\"sa{vol['Date']}*\") if v.is_dir()][0]\n",
    "    # Path to save ALTO files\n",
    "    alto_path = Path(vol_path, \"alto\")\n",
    "    alto_path.mkdir(exist_ok=True)\n",
    "    # Need to look in METS data for the right id\n",
    "    response = sess.get(f\"https://viewerapi.slv.vic.gov.au/?entity={ie_id}&dc_arrays=1\")\n",
    "    vol_data = response.json()\n",
    "    tiff_id = find_tiff_rep(vol_data)\n",
    "    # Loop through files in METS data looking for ALTO files\n",
    "    for file in tqdm(vol_data[\"file\"].values()):\n",
    "        if file.get(\"entity_type\") == \"ALTO\":\n",
    "            # Download ALTO file\n",
    "            alto_response = sess.get(file[\"url\"])\n",
    "            # Get the image id related to the ALTO file\n",
    "            image_id = file[\"related_files\"][tiff_id][\"$ref\"].split(\"][\")[1].strip('\"]')\n",
    "            # Save ALTO XML file using ALTO and image ids in filename (I want to keep the link between text and image for use later)\n",
    "            Path(alto_path, f\"{file[\"id\"]}-{image_id}.xml\").write_text(alto_response.text)\n",
    "            if not alto_response.from_cache:\n",
    "                time.sleep(2)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171ae73-a5b3-4e7a-87c9-343899cb571b",
   "metadata": {},
   "source": [
    "Extract the page text from each ALTO file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad774ee6-8485-4010-b9da-ea72ad86a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through volumes, sorted by date\n",
    "for i, vol in df.sort_values(\"Date\").iterrows():\n",
    "    print(vol[\"Date\"])\n",
    "    ie_id = vol[\"ie_id\"]\n",
    "    # Path to volume data\n",
    "    vol_path = [v for v in Path(\"sands_and_mac\").glob(f\"sa{vol['Date']}*\") if v.is_dir()][0]\n",
    "    # Path where ALTO files are saved\n",
    "    alto_path = Path(vol_path, \"alto\")\n",
    "    # Path to save text from ALTO files\n",
    "    alto_text = Path(vol_path, \"alto-text\")\n",
    "    alto_text.mkdir(exist_ok=True)\n",
    "    # Loop through all the ALTO XML files\n",
    "    for alto_file in tqdm(alto_path.glob(\"*.xml\")):\n",
    "        soup = BeautifulSoup(alto_file.read_text(), features=\"xml\")\n",
    "        # Open a text file to save the lines of text\n",
    "        with Path(alto_text, f\"{alto_file.stem}.txt\").open(\"w\") as alto_text_file:\n",
    "            # Extract the words from each line and write them as a single string to the text file\n",
    "            for line in soup.find_all(\"TextLine\"):\n",
    "                words = []\n",
    "                for word in line.find_all(\"String\"):\n",
    "                    words.append(word[\"CONTENT\"].strip())\n",
    "                alto_text_file.write((\" \".join(words)) + \"\\n\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
